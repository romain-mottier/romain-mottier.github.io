{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feuille de travaux pratiques. Résolution numérique d'équations non linéaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chargement des bibliothèques\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 (méthodes de dichotomie et de Newton-Raphson, d'après A. Quarteroni)\n",
    "\n",
    "Dans cet exercice, on souhaite utiliser sur des exemples différentes méthodes d'approximation d'un zéro d'une fonction.\n",
    "\n",
    "**1.** On considère tout d'abord la fonction\n",
    "$$\n",
    "f(x)=\\frac{x}{2}-\\sin(x)+\\frac{\\pi}{6}-\\frac{\\sqrt{3}}{2}\n",
    "$$\n",
    "sur l'intervalle $\\left[-\\frac{\\pi}{2},\\pi\\right]$, en observant qu'elle y possède deux zéros.\n",
    "\n",
    "**(a)** &Eacute;crire une fonction `f` prenant en entrée un réel $x$ et renvoyant la valeur de $f(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 0.5*x-np.sin(x)+np.pi/6-0.5*np.sqrt(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** À l'aide du graphe de la fonction $f$ sur $\\left[-\\frac{\\pi}{2},\\pi\\right]$, expliquer pourquoi la [méthode de dichotomie](http://fr.wikipedia.org/wiki/M%C3%A9thode_de_dichotomie) ne peut être utilisée que pour approcher l'un des deux zéros de $f$, que l'on notera $\\xi$ dans la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "x=np.linspace(-np.pi/2,np.pi,num=500)\n",
    "plt.plot(x,f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphe montre l'existence de deux zéros réels pour la fonction $f$, l'un positif, l'autre négatif. La méthode de dichotomie ne permettant d'approcher que des zéros en lesquels la fonction change de signe, on constate que l'on ne peut utiliser cette méthode que pour déterminer l'un des deux zéros, noté $\\xi$, qui se trouve compris entre 2 et 3 (on a en effet $f(2)f(3)<0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Écrire une fonction `[zero,iter,res,inc]=dichotomie(f,a,b,tol,itermax)` mettant en &oelig;uvre la méthode de dichotomie pour l'approximation d'un zéro d'une fonction $f$ donnée, compris dans un intervalle $[a,b]$ tel que $f(a)f(b)<0$. En plus de la fonction et des bornes de l'intervalle, les autre paramètres d'entrée seront une tolérance `tol` pour le critère d'arrêt de la méthode et un nombre maximum `itermax` d'itérations à effectuer. Elle reverra en sortie l'approximation du zéro obtenue `zero`, le nombre d'itérations\n",
    "nécessaire au calcul de cette approximation `iter`, la valeur `res` de la fonction $f$ en cette approximationt et un vecteur `inc` contenant la suite des valeurs absolues des différences entre deux approximations successives (dite suite des incréments). On réfléchira au choix du critère d'arrêt à employer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rappelle que la méthode de dichotomie pour l'approximation d'un zéro d'une fonction $f$ contenu dans un intervalle $[a,b]$ tel que $f(a)f(b)<0$ consiste, pour tout entier naturel $k$ et à partir des initialisations $a^{(0)}=a$ et $b^{(0)}=b$,\n",
    "\n",
    "* à définir une approximation du zéro $x^{(k)}=\\frac{a^{(k)}+b^{(k)}}{2}$,\n",
    "* à poser $a^{(k+1)}=a^{(k)}$ et $b^{(k+1)}=x^{(k)}$ si $f(a^{(k)})f(x^{(k)})<0$, $a^{(k+1)}=x^{(k)}$ et $b^{(k+1)}=b^{(k)}$ si $f(x^{(k)})f(b^{(k)})<0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dichotomie(f,a,b,tol,itermax):\n",
    "    fa,fb=f(a),f(b)\n",
    "    if fa*fb>0:\n",
    "        raise ValueError('Le signe de la fonction doit différer en chaque extrémité de l\\'intervalle.')\n",
    "    iter=1\n",
    "    ak,bk=a,b\n",
    "    xk=0.5*(ak+bk)\n",
    "    res=f(xk)\n",
    "    inc=[abs(bk-xk)]\n",
    "    while (abs(res)>=tol and inc[-1]>=tol and iter<=itermax):\n",
    "        iter=iter+1\n",
    "        if res*fa>0:\n",
    "            ak=xk\n",
    "            fa=res\n",
    "        elif res*fa<0:\n",
    "            bk=xk\n",
    "            fb=res\n",
    "        else:\n",
    "            return [xk,iter,res,inc]\n",
    "        inc.append(0.5*inc[-1])\n",
    "        xk=0.5*(ak+bk)\n",
    "        res=f(xk)\n",
    "    if iter>itermax:\n",
    "        print('Le nombre maximum d\\'itérations a été atteint sans convergence avec la tolérance désirée.')\n",
    "    return [xk,iter,res,inc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Utiliser la fonction `dichotomie` pour calculer une approximation de $\\xi$ avec une tolérance égale à $10^{-10}$ pour le critère d'arrêt à partir du choix d'un intervalle $[a,b]$ convenable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[xi,iter,res,inc]=dichotomie(f,2.,3.,1e-10,1000)\n",
    "print('Approximation de xi obtenue par la méthode de dichotomie :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** Au moyen de la commande `semilogy`, tracer le graphe de la suite des incréments $|x^{(k+1)}-x^{(k)}|$ en fonction de $k$ avec une échelle semilogarithmique et déterminer la loi selon laquelle ces quantités tendent vers $0$ quand $k$ tend vers l'infini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.semilogy(inc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient une droite, ce qui implique que la quantité $|x^{(k+1)}−x^{(k)}|$ à l'étape $k$ vaut approximativement $C^k|x^{(1)}−x^{(0)}|$, où $C=10^p$ est une constante et l'exposant $p$ est égal à la pente de la droite. Calculons la valeur de cette pente et la constante $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p=(np.log10(inc[iter-2])-np.log10(inc[0]))/(iter-2)\n",
    "print('Pente de la droite :',p)\n",
    "print('Valeur de la constante C :',pow(10,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on pouvait s'en douter, la loi suivie par les incréments est donc\n",
    "$$\n",
    "\\forall k\\in\\mathbb{N},\\ |x^{(k+1)}−x^{(k)}|=\\frac{1}{2^k}|x^{(1)}−x^{(0)}|.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)** Écrire une fonction `[zero,iter,res,inc]=newton(f,df,x0,tol,itermax)` qui met en &oelig;uvre la [méthode de Newton-Raphson](http://fr.wikipedia.org/wiki/M%C3%A9thode_de_Newton) pour l'approximation d'un zéro d'une fonction dérivable $f$ donnée. Les paramètres d'entrée `df`, `x0`, `tol` et `itermax` représenteront respectivement la fonction correspondant à la fonction dérivée $f'$, l'initialisation de la suite des approximations, la tolérance pour le critère d'arrêt de la méthode et le nombre maximum d'itérations à effectuer. En sortie, les paramètres seront identiques à ceux de la fonction `dichotomie`. La encore, on réfléchira au choix du critère d'arrêt à employer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rappelle que la méthode de Newton-Raphson pour l'approximation d'un zéro d'une fonction $f$ dérivable consiste, à partir d'une initialisation $x^{(0)}$ donnéee, en la construction d'une suite d'approximations du zéro définie par la relation de récurrence\n",
    "$$\n",
    "\\forall k\\in\\mathbb{N},\\ x^{(k+1)}=x^{(k)}−\\frac{f(x^{(k)})}{f'(x^{(k)})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(f,df,x0,tol,itermax):\n",
    "    x=x0\n",
    "    inc=[]\n",
    "    iter=0\n",
    "    diff=tol+1\n",
    "    while (abs(diff)>=tol and iter<=itermax):\n",
    "        iter=iter+1\n",
    "        fx,dfx=f(x),df(x)\n",
    "        diff=-fx/dfx\n",
    "        x=x+diff\n",
    "        inc.append(abs(diff))\n",
    "    if iter>itermax:\n",
    "        print('Le nombre maximum d\\'itérations a été atteint sans convergence avec la tolérance désirée.')\n",
    "    return [x,iter,f(x),inc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g)** Calculer des approximations des deux zéros $\\xi$ et $\\zeta$ de la fonction $f$ avec la méthode de Newton-Raphson, en prenant une tolérance égale à $10^{-10}$ pour le critère d'arrêt et comme initialisations le point $\\pi$ pour $\\xi$ et $-\\frac{\\pi}{2}$ pour $\\zeta$. Comparer les nombres d'itérations effectuées pour obtenir une approximation de chacun des zéros. Pourquoi sont-ils très différents ? Comparer également les graphes des suites des incréments obtenus avec la commande `semilogy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def df(x):\n",
    "    return 0.5-np.cos(x)\n",
    "\n",
    "[xi,iter_xi,res,inc_xi]=newton(f,df,np.pi,1e-10,1000)\n",
    "print('Approximation de xi obtenue par la méthode de Newton-Raphson :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter_xi)\n",
    "[zeta,iter_zeta,res,inc_zeta]=newton(f,df,-0.5*np.pi,1e-10,1000)\n",
    "print('Approximation de zeta obtenue par la méthode de Newton-Raphson :',zeta)\n",
    "print('Nombre d\\'itérations nécessaires :',iter_zeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La différence entre le nombre d'itérations nécessaires pour l'obtention de chaque zéro s'explique par le fait que $f'(\\zeta)=0$ (on dit que ce zéro est de multiplicité double), la méthode de Newton-Raphson ne converge donc que linéairement vers ce zéro, ce que l'on conrfime en traçant les graphes des suites des incréments calculées pour chacune des approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.semilogy(inc_xi,label='incréments approx. $\\\\xi$ (Newton)')\n",
    "plt.semilogy(inc_zeta,label='incréments approx. $\\\\zeta$ (Newton)')\n",
    "plt.legend() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h)** On cherche à réduire le nombre d'itérations nécessaires à l'obtention d'une approximation du zéro négatif $\\zeta$ de la fonction $f$. La méthode de Newton-Raphson modifiée, basée sur la modification suivante de la relation de récurrence de la méthode de Newton-Raphson\n",
    "$$\n",
    "\\forall k\\in\\mathbb{N},\\ x^{(k+1)}=x^{(k)}−2\\frac{f(x^{(k)})}{f'(x^{(k)})},\n",
    "$$\n",
    "a une convergence quadratique si $f'(\\zeta)=0$. Mettre en &oelig;uvre cette méthode dans une fonction `modnewton` et voir combien d'itérations sont nécessaires pour qu'elle fournisse une approximation de $\\zeta$ avec une tolérance égale à $10^{-10}$ pour le critère d'arrêt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On modifie le code de la fonction `newton` précédemment écrite pour tenir compte de la multiplicité du zéro approché."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modnewton(f,df,m,x0,tol,itermax):\n",
    "    x=x0\n",
    "    inc=[]\n",
    "    iter=0\n",
    "    diff=tol+1\n",
    "    while (abs(diff)>=tol and iter<=itermax):\n",
    "        iter=iter+1\n",
    "        fx,dfx=f(x),df(x)\n",
    "        diff=-m*fx/dfx\n",
    "        x=x+diff\n",
    "        inc.append(abs(diff))\n",
    "    if iter>itermax:\n",
    "        print('Le nombre maximum d\\'itérations a été atteint sans convergence avec la tolérance désirée.')\n",
    "    return [x,iter,f(x),inc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise cette nouvelle fonction pour approcher $\\zeta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[zeta,iter,res,inc]=modnewton(f,df,2,-0.5*np.pi,1e-10,1000)\n",
    "print('Approximation de zeta obtenue par la méthode de Newton-Raphson modifiée :',zeta)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "plt.grid()\n",
    "plt.semilogy(inc_xi,label='incréments approx. $\\\\xi$ (Newton)')\n",
    "plt.semilogy(inc_zeta,label='incréments approx. $\\\\zeta$ (Newton)')\n",
    "plt.semilogy(inc,label='incréments approx. $\\\\zeta$ (Newton modifiée)')\n",
    "plt.legend() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** On considère à présent la fonction $g(x)=x+e^{-20\\,x^2}\\cos(x)$, dont on veut approcher les zéros par la méthode de Newton-Raphson.\n",
    "\n",
    "**(a)** &Eacute;crire une fonction `g` pour la fonction $g$ et une fonction `dg` pour sa dérivée $g'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    return x+np.exp(-20*pow(x,2))*np.cos(x)\n",
    "\n",
    "def dg(x):\n",
    "    return 1-(40*x*np.cos(x)+np.sin(x))*np.exp(-20*pow(x,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Utiliser la fonction `newton` pour essayer d'approcher d'un zéro de $g$ en prenant $x^{(0)}=0$ pour initialisation et une tolérance égale à $10^{-10}$ pour le critère d'arrêt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[zero,iter,res,inc]=newton(g,dg,0,1e-10,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que la méthode de Newton-Raphson n'a pas convergé après mille itérations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Tracer le graphe de $g$ sur l'intervalle $[-1,1]$ et tenter de donner une explication qualitative du fait la méthode de Newton-Raphson ne converge pas avec l'initialisation précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "x=np.linspace(-1,1,200)\n",
    "plt.plot(x,g(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On explique l'absence de convergence de la méthode par que le fait la fonction $g$ prend en $x=0$ et $x=−1$ des valeurs opposées, alors que sa dérivée $g'$ prend en ces points des valeurs pratiquement égales. La suite produite à partir du choix $x^{(0)}=0$ est alors périodique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Appliquer cinq intérations de la méthode de dichotomie à la fonction $g$ sur l'intervalle $[-1,1]$ et utiliser le point obtenu comme initialisation de la méthode de Newton-Raphson pour la recherche d'un zéro de $g$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[x0,iter,res,inc]=dichotomie(g,-1.,1.,1e-10,5)\n",
    "print('Initialisation obtenue par la méthode de dichotomie :',x0)\n",
    "[zero,iter,res,inc]=newton(g,dg,x0,1e-10,1000)\n",
    "print('Approximation du zéro de de g obtenue par la méthode de Newton-Raphson :',zero)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Modifier la fonction `dichotomie` pour obtenir une fonction\n",
    "`regulafalsi` mettant en &oelig;uvre la [méthode de la fausse position](http://fr.wikipedia.org/wiki/M%C3%A9thode_de_la_fausse_position). De la même manière,\n",
    "modifier la fonction `newton` pour obtenir une fonction `secante` mettant en &oelig;uvre la [méthode de la sécante](http://fr.wikipedia.org/wiki/M%C3%A9thode_de_la_s%C3%A9cante)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode de la fausse position diffère de la méthode de dichotomie par le choix à chaque étape du point $x^{(k)}$, qui n'est plus le milieu de l'intervalle d'encadrement courant $[a^{(k)},b^{(k)}]$, mais le point d'intersection entre l'axe des abscisses et la droite passant par les points $(a^{(k)},f(a^{(k)}))$ et $(b^{(k)},f(b^{(k)}))$,\n",
    "$$\n",
    "x^{(k)}=a^{(k)}−\\frac{a^{(k)}−b^{(k)}}{f(a^{(k)})−f(b^{(k)})}f(a^{(k)}).\n",
    "$$\n",
    "On modifie donc facilement la fonction `dichotomie` pour programmer la méthode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regulafalsi(f,a,b,tol,itermax):\n",
    "    fa,fb=f(a),f(b)\n",
    "    if fa*fb>0:\n",
    "        raise ValueError('Le signe de la fonction doit différer en chaque extrémité de l\\'intervalle.')\n",
    "    iter=1\n",
    "    ak,bk=a,b\n",
    "    xk=(bk*fa-ak*fb)/(fa-fb)\n",
    "    inc=[abs(bk-xk)]\n",
    "    res=f(xk)\n",
    "    while (abs(res)>=tol and inc[-1]>=tol and iter<=itermax):\n",
    "        iter=iter+1\n",
    "        if res*fa>0:\n",
    "            inc.append(abs(ak-xk))\n",
    "            ak=xk\n",
    "            fa=res\n",
    "        elif res*fa<0:\n",
    "            inc.append(abs(bk-xk))\n",
    "            bk=xk\n",
    "            fb=res\n",
    "        else:\n",
    "            return [xk,iter,res,inc]\n",
    "        xk=(bk*fa-ak*fb)/(fa-fb)\n",
    "        res=f(xk)\n",
    "    if iter>itermax:\n",
    "        print('Le nombre maximum d\\'itérations a été atteint sans convergence avec la tolérance désirée.')\n",
    "    return [xk,iter,res,inc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste cette nouvelle fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 0.5*x-np.sin(x)+np.pi/6-0.5*np.sqrt(3)\n",
    "[xi,iter,res,inc]=regulafalsi(f,2,3,1e-10,1000)\n",
    "print('Approximation de xi obtenue par la méthode de la fausse position :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rappelle que la méthode de la sécante est définie par la relation de récurrence\n",
    "$$\n",
    "\\forall k\\in\\mathbb{N},\\ x^{(k+1)}=x^{(k)}−\\frac{x^{(k)}−x^{(k-1)}}{f(x^{(k)})−f(x^{(k-1)})}f(x^{(k)}),\n",
    "$$\n",
    "et nécessite par conséquent deux valeurs d'initialisation $x^{(0)}$ et $x^{(−1)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secante(f,x0,xm1,tol,itermax):\n",
    "    if (x0==xm1):\n",
    "        raise ValueError('Les deux initialisations données doivent être distinctes.')\n",
    "    fxm1,fx0=f(xm1),f(x0)\n",
    "    inc=[]\n",
    "    iter=0\n",
    "    diff=tol+1\n",
    "    while (abs(diff)>=tol and iter<=itermax):\n",
    "        iter=iter+1\n",
    "        diff=-fx0*(x0-xm1)/(fx0-fxm1)\n",
    "        xm1=x0\n",
    "        fxm1=fx0\n",
    "        x0=x0+diff\n",
    "        fx0=f(x0)\n",
    "        inc.append(abs(diff))\n",
    "    if iter>itermax:\n",
    "        print('Le nombre maximum d\\'itérations a été atteint sans convergence avec la tolérance désirée.')\n",
    "    return [x0,iter,fx0,inc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste cette dernière fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[xi,iter,res,inc]=secante(f,np.pi,np.pi-0.5,1e-10,1000)\n",
    "print('Approximation de xi obtenue par la méthode de la sécante :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice bonus (variantes de la méthode de la fausse position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le phénomène de rétention d'une des bornes d'encadrement observé lors de l'application de la méthode de la fausse position à la résolution numérique d'une équation non linéaire dans $\\mathbb{R}$ a pour effet de diminuer sa vitesse de convergence, ce qui la rend parfois moins efficace que la méthode de dichotomie. Pour corriger ce défaut, plusieurs variantes ont été introduites. On propose dans cet exercice de les tester sur quelques exemples.\n",
    "\n",
    "Pour décrire de manière explicite ces modifications, on adopte les notations suivantes. On suppose disposer initialement d'un intervalle $[x^{(0)},x^{(1)}]$ non vide de $\\mathbb{R}$ et d'une application continue $f$ de $[x^{(0)},x^{(1)}]$ dans $\\mathbb{R}$, telle que $f(x^{(0)})f(x^{(1)})<0$, ce qui assure l'existence d'un zéro $\\xi$ de $f$. On pose alors $y^{(0)}=f(x^{(0)})$ et $y^{(1)}=f(x^{(1)})$. À l'étape $k$, avec $k$ un entier naturel non nul, on pose\n",
    "$$\n",
    "x^{(k+1)}=\\frac{x^{(k-1)}y^{(k)}-x^{(k)}y^{(k-1)}}{y^{(k)}-y^{(k-1)}}\\text{ et }y^{(k+1)}=f(x^{(k+1)}).\n",
    "$$\n",
    "Si $y^{(k+1)}y^{(k)}<0$, on passe à l'étape suivante. En revanche, si $y^{(k+1)}y^{(k)}>0$, on fait la mise à jour suivante\n",
    "$$\n",
    "x^{(k)}=x^{(k-1)}\\text{ et }y^{(k)}=\\alpha\\,y^{(k-1)}\n",
    "$$\n",
    "avant de passer à l'étape suivante, avec\n",
    "* $\\alpha=\\frac{1}{2}$ pour la <a href=\"https://doi.org/10.1007/BF01934364\">méthode Illinois</a>,\n",
    "* $\\alpha=\\frac{y^{(k)}}{y^{(k)}+y^{(k+1)}}$ pour la <a href=\"https://doi.org/10.1007/BF01932959\">méthode Pegasus</a>,\n",
    "* $\\alpha=\\frac{y^{(k)}-y^{(k+1)}}{y^{(k)}}$ si cette quantité est strictement positive, $\\alpha=\\frac{1}{2}$ sinon, pour la <a href=\"https://doi.org/10.1007/BF01951936\">méthode d'Anderson-Björck</a>.\n",
    "\n",
    "**1.** Sur le modèle de la fonction `regulafalsi` écrite dans l'exercice précédent, écrire des fonctions mettant en &oelig;uvre chacune des variantes données ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def illinois(f,a,b,tol,itermax):\n",
    "    fa,fb=f(a),f(b)\n",
    "    if fa*fb>0:\n",
    "        raise ValueError('Le signe de la fonction doit différer en chaque extrémité de l\\'intervalle.')\n",
    "    iter=1\n",
    "    ak,bk=a,b\n",
    "    xk=(bk*fa-ak*fb)/(fa-fb)\n",
    "    inc=[abs(bk-xk)]\n",
    "    res=f(xk)\n",
    "    while (abs(res)>=tol and inc[-1]>=tol and iter<=itermax):\n",
    "        iter=iter+1\n",
    "        if res*fb>0:\n",
    "            fa=0.5*fa\n",
    "        elif res*fb<0:\n",
    "            ak=bk\n",
    "            fa=fb\n",
    "        else:\n",
    "            return [xk,iter,res,inc]\n",
    "        inc.append(abs(bk-xk))\n",
    "        bk=xk\n",
    "        fb=res\n",
    "        xk=(bk*fa-ak*fb)/(fa-fb)\n",
    "        res=f(xk)\n",
    "    if iter>itermax:\n",
    "        print('Le nombre maximum d\\'itérations a été atteint sans convergence avec la tolérance désirée.')\n",
    "    return [xk,iter,res,inc]\n",
    "\n",
    "def pegasus(f,a,b,tol,itermax):\n",
    "    fa,fb=f(a),f(b)\n",
    "    if fa*fb>0:\n",
    "        raise ValueError('Le signe de la fonction doit différer en chaque extrémité de l\\'intervalle.')\n",
    "    iter=1\n",
    "    ak,bk=a,b\n",
    "    xk=(bk*fa-ak*fb)/(fa-fb)\n",
    "    inc=[abs(bk-xk)]\n",
    "    res=f(xk)\n",
    "    while (abs(res)>=tol and inc[-1]>=tol and iter<=itermax):\n",
    "        iter=iter+1\n",
    "        if res*fb>0:\n",
    "            fa=fa*fb/(fb+res)\n",
    "        elif res*fb<0:\n",
    "            ak=bk\n",
    "            fa=fb\n",
    "        else:\n",
    "            return [xk,iter,res,inc]\n",
    "        inc.append(abs(bk-xk))\n",
    "        bk=xk\n",
    "        fb=res\n",
    "        xk=(bk*fa-ak*fb)/(fa-fb)\n",
    "        res=f(xk)\n",
    "    if iter>itermax:\n",
    "        print('Le nombre maximum d\\'itérations a été atteint sans convergence avec la tolérance désirée.')\n",
    "    return [xk,iter,res,inc]\n",
    "\n",
    "def anderson_bjorck(f,a,b,tol,itermax):\n",
    "    fa,fb=f(a),f(b)\n",
    "    if fa*fb>0:\n",
    "        raise ValueError('Le signe de la fonction doit différer en chaque extrémité de l\\'intervalle.')\n",
    "    iter=1\n",
    "    ak,bk=a,b\n",
    "    xk=(bk*fa-ak*fb)/(fa-fb)\n",
    "    inc=[abs(bk-xk)]\n",
    "    res=f(xk)\n",
    "    while (abs(res)>=tol and inc[-1]>=tol and iter<=itermax):\n",
    "        iter=iter+1\n",
    "        if res*fb>0:\n",
    "            reduction_factor=(fb-res)/fb\n",
    "            if reduction_factor>0:\n",
    "                fa=reduction_factor*fa\n",
    "            else:\n",
    "                fa=0.5*fa\n",
    "        elif res*fb<0:\n",
    "            ak=bk\n",
    "            fa=fb\n",
    "        else:\n",
    "            return [xk,iter,res,inc]\n",
    "        inc.append(abs(bk-xk))\n",
    "        bk=xk\n",
    "        fb=res\n",
    "        xk=(bk*fa-ak*fb)/(fa-fb)\n",
    "        res=f(xk)\n",
    "    if iter>itermax:\n",
    "        print('Le nombre maximum d\\'itérations a été atteint sans convergence avec la tolérance désirée.')\n",
    "    return [xk,iter,res,inc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Tester ces fonctions, ainsi que les fonctions `dichotomie` et `regulafalsi`, pour la détermination du zéro de la fonction $f(x)=11x^{11}-1$. On utilisera l'intervalle $\\left[\\frac{1}{10},1\\right]$ comme encadrement initial et une tolérance égale à $10^{-12}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 11*pow(x,11)-1.\n",
    "\n",
    "[xi,iter,res,inc]=dichotomie(f,0.1,1.,1e-12,100)\n",
    "print('Approximation de xi obtenue par la méthode de dichotomie :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "[xi,iter,res,inc]=regulafalsi(f,0.1,1.,1e-12,100)\n",
    "print('Approximation de xi obtenue par la méthode de la fausse position :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "[xi,iter,res,inc]=illinois(f,0.1,1.,1e-12,100)\n",
    "print('Approximation de xi obtenue par la méthode Illinois :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "[xi,iter,res,inc]=pegasus(f,0.1,1.,1e-12,100)\n",
    "print('Approximation de xi obtenue par la méthode Pegasus :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "[xi,iter,res,inc]=anderson_bjorck(f,0.1,1.,1e-12,100)\n",
    "print('Approximation de xi obtenue par la méthode d\\'Anderson-Björck :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Reprendre la question précédente avec la fonction $f(x)=1-\\frac{1}{x^5}$. On utilisera l'intervalle $\\left[\\frac{1}{2},2\\right]$ comme encadrement initial et une tolérance égale à $10^{-12}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 1.-1./pow(x,5)\n",
    "\n",
    "[xi,iter,res,inc]=dichotomie(f,.5,2.,1e-12,1000)\n",
    "print('Approximation de xi obtenue par la méthode de dichotomie :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "[xi,iter,res,inc]=regulafalsi(f,.5,2.,1e-12,1000)\n",
    "print('Approximation de xi obtenue par la méthode de la fausse position :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "[xi,iter,res,inc]=illinois(f,.5,2.,1e-12,100)\n",
    "print('Approximation de xi obtenue par la méthode Illinois :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "[xi,iter,res,inc]=pegasus(f,.5,2.,1e-12,100)\n",
    "print('Approximation de xi obtenue par la méthode Pegasus :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "[xi,iter,res,inc]=anderson_bjorck(f,.5,2.,1e-12,100)\n",
    "print('Approximation de xi obtenue par la méthode d\\'Anderson-Björck :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Reprendre la question précédente avec la fonction $f(x)=1-\\frac{1}{x}$. On utilisera l'intervalle $\\left[\\frac{1}{2},2\\right]$ comme encadrement initial et une tolérance égale à $10^{-12}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 1.-1./x\n",
    "\n",
    "[xi,iter,res,inc]=dichotomie(f,.5,2.,1e-12,1000)\n",
    "print('Approximation de xi obtenue par la méthode de dichotomie :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "[xi,iter,res,inc]=regulafalsi(f,.5,2.,1e-12,1000)\n",
    "print('Approximation de xi obtenue par la méthode de la fausse position :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "[xi,iter,res,inc]=illinois(f,.5,2.,1e-12,100)\n",
    "print('Approximation de xi obtenue par la méthode Illinois :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "[xi,iter,res,inc]=pegasus(f,.5,2.,1e-12,100)\n",
    "print('Approximation de xi obtenue par la méthode Pegasus :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "[xi,iter,res,inc]=anderson_bjorck(f,.5,2.,1e-12,100)\n",
    "print('Approximation de xi obtenue par la méthode d\\'Anderson-Björck :',xi)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercice 2 (calcul de $\\sqrt{2}$)\n",
    "Dans cet exercice, on cherche à calculer une approximation de $\\sqrt{2}$ de diverses façons.\n",
    "\n",
    "**1.** On peut tout d'abord obtenir une valeur approchée de $\\sqrt{2}$ en cherchant la racine positive de la fonction polynomiale $f(x)=x^2-2$. Pour cela, appliquer successivement à $f$ les méthodes de dichotomie et de de la fausse position sur l'intervalle $[1,2]$, de Newton-Raphson et de la sécante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return pow(x,2)-2.\n",
    "\n",
    "[zero,iter,res,inc]=dichotomie(f,1,2,1e-10,1000)\n",
    "print('Approximation de la racine carrée de 2 obtenue par la méthode de dichotomie :',zero)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "print('Erreur absolue avec la valeur fournie par sqrt(2) :',abs(zero-np.sqrt(2.)))\n",
    "\n",
    "[zero,iter,res,inc]=regulafalsi(f,1,2,1e-10,1000)\n",
    "print('Approximation de la racine carrée de 2 obtenue par la méthode de la fausse position :',zero)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "print('Erreur absolue avec la valeur fournie par sqrt(2) :',abs(zero-np.sqrt(2.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On initialise la méthode de Newton-Raphson avec le point milieu de l'intervalle $[1,2]$ et la méthode de la sécante avec les bornes $1$ et $2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df(x):\n",
    "    return 2.*x\n",
    "\n",
    "[zero,iter,res,inc]=newton(f,df,1.5,1e-10,1000)\n",
    "print('Approximation de la racine carrée de 2 obtenue par la méthode de Newton-Raphson :',zero)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "print('Erreur absolue avec la valeur fournie par sqrt(2) :',abs(zero-np.sqrt(2.)))\n",
    "\n",
    "[zero,iter,res,inc]=secante(f,1,2,1e-10,1000)\n",
    "print('Approximation de la racine carrée de 2 obtenue par la méthode de la sécante :',zero)\n",
    "print('Nombre d\\'itérations nécessaires :',iter)\n",
    "print('Erreur absolue avec la valeur fournie par sqrt(2) :',abs(zero-np.sqrt(2.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**2.** On peut également se servir de méthodes de point fixe, définies à partir des applications suivantes\n",
    "$$\n",
    "g_1(x)=2+x-x^2,\\ g_2(x)=\\frac{2}{x}\\text{ et }g_3(x)=\\frac{x+2}{x+1},\n",
    "$$\n",
    "considérées sur l'intervalle $[1,2]$.\n",
    "\n",
    "**(a)** Parmi les trois fonctions ci-dessus, lesquelles conduisent à une méthode de point fixe convergente ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après un résultat du cours, on a convergence d'une méthode de point fixe associée à une fonction $g$, définie sur un intervalle $[a,b]$ et à valeurs dans ce même intervalle, s'il existe une constante $0<K<1$ telle que, pour tout $x$ dans $[a,b]$, $|g'(x)|\\leq K$ (la fonction $g$ étant alors dite _contractante_). Traçons les graphes des trois fonctions proposées et des valeurs absolues de leurs dérivées sur l'intervalle $[1,2]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(1,2,100)\n",
    "\n",
    "def g1(x):\n",
    "    return 2.+x-pow(x,2)\n",
    "\n",
    "def dg1(x):\n",
    "    return 1.-2*x\n",
    "\n",
    "plt.grid()\n",
    "plt.plot(x,g1(x),label='$g_1(x)$')\n",
    "plt.plot(x,abs(dg1(x)),label='$|g_1\\'(x)|$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g2(x):\n",
    "    return 2./x\n",
    "\n",
    "def dg2(x):\n",
    "    return -2./pow(x,2)\n",
    "\n",
    "plt.grid()\n",
    "plt.plot(x,g2(x),label='$g_2(x)$')\n",
    "plt.plot(x,abs(dg2(x)),label='$|g_2\\'(x)|$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def g3(x):\n",
    "    return (x+2.)/(x+1.)\n",
    "\n",
    "def dg3(x):\n",
    "    return -pow(x+1.,-2)\n",
    "\n",
    "plt.grid()\n",
    "plt.plot(x,g3(x),label='$g_3(x)$')\n",
    "plt.plot(x,abs(dg3(x)),label='$|g_3\\'(x)|$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On déduit de ces graphes que seule la fonction $g_3$ verifie les hypothèses requises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Vérifier cette affirmation en calculant les vingt premiers termes des suites définies par les relations de récurrence\n",
    "$$\n",
    "x^{(0)}=\\frac{1}{2}\\text{ et },\\forall k\\in\\mathbb{N},\\ x^{(k+1)}=g_i(x^{(k)}),\\ i\\in\\{1,2,3\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=20\n",
    "\n",
    "x1,x2,x3=[0]*n,[0]*n,[0]*n\n",
    "\n",
    "x1[0],x2[0],x3[0]=0.5,0.5,0.5\n",
    "\n",
    "for i in range(n-1):\n",
    "    x1[i+1],x2[i+1],x3[i+1]=g1(x1[i]),g2(x2[i]),g3(x3[i])\n",
    "\n",
    "print('Termes de la suite construite avec g_1 :',x1)\n",
    "print('Termes de la suite construite avec g_2 :',x2)\n",
    "print('Termes de la suite construite avec g_3 :',x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 (bassins de convergence de la méthode de Newton-Raphson)\n",
    "\n",
    "On s'intéresse à la recherche des solutions complexes de l'équation $z^3=1$ par la méthode de Newton-Raphson. On considère pour cela la fonction d'une variable complexe $f(z)=z^3-1$, qui s'annule en chaque point $z$ du plan complexe tel que $z^3=1$.\n",
    "\n",
    "**1.** &Eacute;crire deux fonctions `f` et `df` renvoyant respectivement les valeurs de $f(z)$ et de $f'(z)$ en un point quelconque $z$ de $\\mathbb{C}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return pow(x,3)-1.\n",
    "\n",
    "def df(x):\n",
    "    return 3.*pow(x,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Pour tout entier naturel $n$ supérieur ou égal à $2$, on définit une grille de pas $h=\\frac{3}{n-1}$ couvrant le carré $[-1,5,1,5]\\times[-1,5\\mathrm{i},1,5\\mathrm{i}]$.\n",
    "\n",
    "&Eacute;crire un programme résolvant, pour une valeur donnée de $n$, l'équation $f(z)=0$ avec une tolérance égale à $10^{-4}$ par la méthode de Newton-Raphson utilisant successivement chaque point de la grille $z_{ij}=-1,5(1+\\mathrm{i})+(i+\\mathrm{i}j)h$, $0\\leq i,j\\leq n$ comme initialisation. Pour chaque couple $(i,j)$, stocker dans le tableau à deux dimensions `nrac` le numéro $k$ ($k=0$, $1$ ou $2$) de la racine cubique complexe de l'unité $e^{\\mathrm{i}\\frac{2k\\pi}{3}}$ vers laquelle la méthode aura convergée à partir de $z_{ij}$ (on posera $k=3$ lorsque la méthode n'a pas convergé après $100$ itérations) et dans le tableau `niter` le nombre d'itérations nécessaires pour atteindre la convergence (en stockant le nombre maximal d'itérations autorisées en l'absence de convergence).\n",
    "\n",
    "Pour automatiser le processus de reconnaissance de la racine approchée par la valeur `zero` renvoyée, on pourra utiliser les instructions suivantes (ci-dessous, `racines` désigne un tableau contenant les trois racines cubiques complexes de l'unité et `tol` est la tolérance du critère d'arrêt de la méthode de Newton-Raphson) :\n",
    "\n",
    "`d=racines-[zero,zero,zero]\n",
    " m,k=min(abs(d)),argmin(abs(d))\n",
    " if (abs(m)>tol):\n",
    "     k=3`\n",
    "     \n",
    "Lancer le programme avec $n$ valant $100$ et une tolérance fixée à $10^{-4}$ (compte tenu du nombre important d'appels de la méthode de Newton--Raphson)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "racines=np.cos(2*np.pi*np.arange(3)/3)+1j*np.sin(2*np.pi*np.arange(3)/3)\n",
    "\n",
    "n=100\n",
    "tol=1e-4\n",
    "\n",
    "x=np.linspace(-1.5,1.5,n+1)\n",
    "niter,nrac=np.zeros((n+1,n+1)),np.zeros((n+1,n+1))\n",
    "for i in range(n+1):\n",
    "    for j in range(n+1):\n",
    "        [zero,iter,res,inc]=newton(f,df,x[i]+1j*x[j],tol,100)\n",
    "        niter[i,j]=iter\n",
    "        d=racines-[zero,zero,zero]\n",
    "        m,k=min(abs(d)),np.argmin(abs(d))\n",
    "        if (abs(m)>tol):\n",
    "            k=3\n",
    "        nrac[i,j]=k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** &Agrave; l'aide des commandes `matshow(nrac.T)` et `matshow(niter.T)`, afficher une représentation des bassins de convergence de la méthode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2)\n",
    "fig.set_size_inches(15,15)\n",
    "ax1.matshow(nrac.T)\n",
    "ax2.matshow(niter.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Refaire des tracés pour des pas de grille plus petits (c'est-à-dire de plus grandes valeurs de $n$). Que dire des &laquo; frontières &raquo; des trois bassins de convergence de la méthode ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n=500\n",
    "\n",
    "x=np.linspace(-1.5,1.5,n+1)\n",
    "niter,nrac=np.zeros((n+1,n+1)),np.zeros((n+1,n+1))\n",
    "for i in range(n+1):\n",
    "    for j in range(n+1):\n",
    "        [zero,iter,res,inc]=newton(f,df,x[i]+1j*x[j],tol,100)\n",
    "        niter[i,j]=iter\n",
    "        d=racines-[zero,zero,zero]\n",
    "        m,k=min(abs(d)),np.argmin(abs(d))\n",
    "        if (abs(m)>tol):\n",
    "            k=3\n",
    "        nrac[i,j]=k\n",
    "        \n",
    "fig,(ax1,ax2)=plt.subplots(1,2)\n",
    "fig.set_size_inches(15,15)\n",
    "ax1.matshow(nrac.T)\n",
    "ax2.matshow(niter.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec une résolution plus fine, on observe clairement que les bassins de convergence de la méthodes ne sont pas délimités de manière nette. Au contraire, cette frontière est [fractale](http://fr.wikipedia.org/wiki/Fractale) et présente une structure visuellement complexe, caractéristique d'un [ensemble de Mandelbrot](http://fr.wikipedia.org/wiki/Ensemble_de_Mandelbrot). Dans cette région, une perturbation de l'initialisation fait converger la méthode vers une toute autre solution de l'équation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
